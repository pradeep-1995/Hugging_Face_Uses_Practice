{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMezybbtt1l7HxV4bXrVgMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeep-1995/Hugging_Face_Uses_Practice/blob/main/Speak_to_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imiWUKTkwTvV"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "import torch\n",
        "import IPython.display as display\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "7dbcZPtLx7RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ],
      "metadata": {
        "id": "6MOPx5EiygDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Wav2Vec2Tokenizer.form_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ],
      "metadata": {
        "id": "VXbqc1EDypY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sampling_rate = librosa.load(\"audio.wav\", sr=16000)"
      ],
      "metadata": {
        "id": "A6o0VJ26y--Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sampling_rate"
      ],
      "metadata": {
        "id": "m6U0-9hQ11Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display.Audio(\"audio.wav\", autoplay=True)"
      ],
      "metadata": {
        "id": "rM8loZRb16U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_values = tokenizer(audio, return_tensors=\"pt\").input_values\n",
        "input_values"
      ],
      "metadata": {
        "id": "rHVAoeq12NPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(input_values).logits\n",
        "logits"
      ],
      "metadata": {
        "id": "2aObqWub2NCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "predicted_ids"
      ],
      "metadata": {
        "id": "VqnhxWbU2Mzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = tokenizer.decode(predicted_ids[0])\n",
        "transcription"
      ],
      "metadata": {
        "id": "y77HijzW-EH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HBZmrYg9-Dwn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}